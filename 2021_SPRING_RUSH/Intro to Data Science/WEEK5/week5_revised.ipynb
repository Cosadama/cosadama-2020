{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "[1학년]Intro to Data Science_week5.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "j9OYLao0C5cv"
      ]
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyGmczxvC5bu"
      },
      "source": [
        "# 🦉COSADAMA Introduction to Data Science Study\n",
        "\n",
        "- 참고자료: 파이썬으로 데이터 주무르기(민형기), 점프 투 파이썬(박응용), 파이썬 입문과 크롤링 기초 부트캠프(잔재미코딩)\n",
        "- 교재: 125 - 138쪽\n",
        "\n",
        "## 웹 크롤링과 정규 표현식\n",
        "\n",
        "이번 주차에는 드디어 **재밌는 웹 크롤링과 외계어 같은 정규 표현식**에 대해 알아보려고 합니다 🕷🕸\n",
        "\n",
        "웹 크롤링이라는 것은 웹에서 내가 원하는 데이터를 긁어오는 것을 말하는데요, 웹 크롤링을 하면 뭔가 내가 프로그래밍을 배웠긴 배웠구나라는 신기한 생각이 든답니다😀 웹 크롤링도 엄청나게 방대한 기술이 있기 때문에 기초적인 수준을 먼저 다뤄보려 합니다.\n",
        "\n",
        "웹에서 정보를 가져오기 위해서는 **HTML/CSS**에 대한 기본지식이 있어야 하니, 이 또한 필요한 부분(아주 작은 부분)만 뽑아서 학습해 볼 겁니다. 그 후에는 **정규표현식**을 배워 원하는 데이터만 좀 더 편하게가져올 수 있도록 할 것이구요!\n",
        "\n",
        "이번 주차는 학습 분량이 넘칩니다. 너무 많다고요? 어쩔 수 없습니다 ㅎ 정말 줄이고 줄여서 담은 내용이라 하나도 뺄게 없거든요... 😂\n",
        "\n",
        "마음의 준비가 다 되셨나요?\n",
        "\n",
        "준비가 다 되셨다면, **BeatifulSoup과 urllib 라이브러리를 활용해 웹 크롤링**을 해보고, 엑셀을 열고 기록하는데 사용되는 모듈 **openpyxl**을 사용해 가져온 데이터를 엑셀 파일에 저장하고 읽어본 뒤, **정규표현식**을 통해 원하는 데이터만 쏙쏙 골라보러 출발~🏃‍♀️🏃‍♂️\n",
        "\n",
        "### 1. HTML/CSS 기초 \n",
        "\n",
        "웹 크롤링을 하려면 웹이 어떤 문법으로 만들어지는지부터 우선 알아야 합니다. html는 웹 페이지를 만들기 위한 언어로 웹브라우저 위에서 동작하는 언어에요. 웹 페이지 뿐만 아니라 이미지, 텍스트, 비디오의 내용도 담을 수 있습니다. CSS는 간단히 웹 브라우저를 꾸며주는 언어라고 생각하면 되구요. 웹이 어떻게 구성되어 있는지를 이해해야 웹 크롤링도 할 수 있어요. 아래 링크를 보고 해당 부분만 학습하고 오면 됩니다!\n",
        "\n",
        "- [Introduction to HTML](https://www.codecademy.com/learn/learn-html) - syllabus 1. elements & structured의 Introduction to HTML과 HTML Document Standard 학습하기\n",
        "- [Learn CSS](https://www.codecademy.com/learn/learn-css) - syllabus 1. Selectors and Visual Rules의 CSS Setup & Selectors 학습하기\n",
        "\n",
        "\n",
        "- [생활코딩 WEB1 - HTML & Internet](https://opentutorials.org/course/3084) - 처음 ~ HTML 태그의 제왕까지\n",
        "- [생활코딩 WEB2 - CSS](https://opentutorials.org/course/3086) - 처음 ~ CSS 선택자를 스스로 알아내는 방법까지\n",
        "\n",
        "영어, 한글 교육자료를 모두 첨부합니다. 영어 자료는 직접 실습하며 공부할 수 있어요. 생활코딩 강의를 다 들으시고 복습 겸 영어 자료 사이트에 들어가셔서 실습해보시는 것도 추천합니다. 영어, 한글 자료를 모두 공부하실 필요는 없고, 편하신 것으로 공부하시면 됩니다.\n",
        "\n",
        "처음 배우시면 이것을 끝내시는데 하루(3시간 이상) 정도는 걸릴 것 같아요. html/css를 아시는 분들은 이 파트를 넘어가시면 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yScYfrsC5b_"
      },
      "source": [
        "### 2. 웹 데이터를 가져오는 BeautifulSoup \n",
        "\n",
        "- 구글 드라이브의 **02. test_first.html** 다운받기 \n",
        "- [BeautifulSoup4 공식문서](https://www.crummy.com/software/BeautifulSoup/bs4/doc/) - 한글 번역 있음\n",
        "\n",
        "**BeautifulSoup**은 인터넷에서 웹 페이지의 내용을 가져오는 모듈이에요. 웹 크롤링할 때 거의 필수적으로 사용하는 것 같아요. 드라이브에 있는 html 파일을 다운 받으시고 학습하면 됩니다. 더 궁금한 문법이 있다면 위의 공식문서에 한글 번역이 있으니 찬찬히 읽어보는 것도 좋은 방법일 것 같습니다! \n",
        "\n",
        "우선 beautifulsoup을 import 해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFXtHb-AC5cA"
      },
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2kelWAIC5cC"
      },
      "source": [
        "우리는 일단 저장된 html 파일을 읽어오는 것이기 때문에 아래와 같은 방식으로 써줍니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ejyMOoFC5cC",
        "outputId": "fe8a951a-1534-4e12-bd91-7c17ee6b2b02"
      },
      "source": [
        "page = open(\"03. test_first.html\", \"r\").read()\n",
        "soup = BeautifulSoup(page, 'html.parser') # Python’s html.parser - 문서 전체를 저장한 변수 \n",
        "print(soup) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<!DOCTYPE html>\n",
            "\n",
            "<html>\n",
            "<head>\n",
            "<title>Very Simple HTML Code by PinkWink</title>\n",
            "</head>\n",
            "<body>\n",
            "<div>\n",
            "<p class=\"inner-text first-item\" id=\"first\">\n",
            "                Happy PinkWink.\n",
            "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
            "</p>\n",
            "<p class=\"inner-text second-item\">\n",
            "                Happy Data Science.\n",
            "                <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
            "</p>\n",
            "</div>\n",
            "<p class=\"outer-text first-item\" id=\"second\">\n",
            "<b>\n",
            "                Data Science is funny.\n",
            "            </b>\n",
            "</p>\n",
            "<p class=\"outer-text\">\n",
            "<b>\n",
            "                All I need is Love.\n",
            "            </b>\n",
            "</p>\n",
            "</body>\n",
            "</html>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmLo9WNlC5cG"
      },
      "source": [
        "페이지를 이루고 있는 html의 구조가 불러져왔어요~ 더 예쁘게 보고 싶다면 soup.prettify()를 이용하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWf2LdcVC5cG",
        "outputId": "9b6f68a4-2a70-418d-8444-8adeb39dbb03"
      },
      "source": [
        "print(soup.prettify())  # 태그를 구분하기 쉽게 해주는 명령"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<!DOCTYPE html>\n",
            "<html>\n",
            " <head>\n",
            "  <title>\n",
            "   Very Simple HTML Code by PinkWink\n",
            "  </title>\n",
            " </head>\n",
            " <body>\n",
            "  <div>\n",
            "   <p class=\"inner-text first-item\" id=\"first\">\n",
            "    Happy PinkWink.\n",
            "    <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">\n",
            "     PinkWink\n",
            "    </a>\n",
            "   </p>\n",
            "   <p class=\"inner-text second-item\">\n",
            "    Happy Data Science.\n",
            "    <a href=\"https://www.python.org\" id=\"py-link\">\n",
            "     Python\n",
            "    </a>\n",
            "   </p>\n",
            "  </div>\n",
            "  <p class=\"outer-text first-item\" id=\"second\">\n",
            "   <b>\n",
            "    Data Science is funny.\n",
            "   </b>\n",
            "  </p>\n",
            "  <p class=\"outer-text\">\n",
            "   <b>\n",
            "    All I need is Love.\n",
            "   </b>\n",
            "  </p>\n",
            " </body>\n",
            "</html>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0U5cgPwC5cH",
        "outputId": "db503bf9-b9d0-4528-9c54-1eb58172c8be"
      },
      "source": [
        "list(soup.children) # soup에서 한 단계 아래에서 포함된 태그들을 알고 싶으면 children -> list로 묶어라 (인덱싱 위해)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['html', '\\n', <html>\n",
              " <head>\n",
              " <title>Very Simple HTML Code by PinkWink</title>\n",
              " </head>\n",
              " <body>\n",
              " <div>\n",
              " <p class=\"inner-text first-item\" id=\"first\">\n",
              "                 Happy PinkWink.\n",
              "                 <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
              " </p>\n",
              " <p class=\"inner-text second-item\">\n",
              "                 Happy Data Science.\n",
              "                 <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
              " </p>\n",
              " </div>\n",
              " <p class=\"outer-text first-item\" id=\"second\">\n",
              " <b>\n",
              "                 Data Science is funny.\n",
              "             </b>\n",
              " </p>\n",
              " <p class=\"outer-text\">\n",
              " <b>\n",
              "                 All I need is Love.\n",
              "             </b>\n",
              " </p>\n",
              " </body>\n",
              " </html>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ychrQO2cC5cI",
        "outputId": "a70cf9ed-57d0-485d-bc8b-7a021ad7357c"
      },
      "source": [
        "html = list(soup.children)[2] # 리스트의 2번째 요소를 불러와줘\n",
        "html"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<html>\n",
              "<head>\n",
              "<title>Very Simple HTML Code by PinkWink</title>\n",
              "</head>\n",
              "<body>\n",
              "<div>\n",
              "<p class=\"inner-text first-item\" id=\"first\">\n",
              "                Happy PinkWink.\n",
              "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
              "</p>\n",
              "<p class=\"inner-text second-item\">\n",
              "                Happy Data Science.\n",
              "                <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
              "</p>\n",
              "</div>\n",
              "<p class=\"outer-text first-item\" id=\"second\">\n",
              "<b>\n",
              "                Data Science is funny.\n",
              "            </b>\n",
              "</p>\n",
              "<p class=\"outer-text\">\n",
              "<b>\n",
              "                All I need is Love.\n",
              "            </b>\n",
              "</p>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5G5o0cLgC5cK"
      },
      "source": [
        "html 아래에 있는 자식을 가져오고 싶다면, .children을 사용하면 됩니다. 다만 줄바꿈 문자가 있기 때문에 같이 나와요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vk99dzvC5cK",
        "outputId": "168f655b-1860-44ec-b586-2ddc359d6ba7"
      },
      "source": [
        "list(html.children)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n', <head>\n",
              " <title>Very Simple HTML Code by PinkWink</title>\n",
              " </head>, '\\n', <body>\n",
              " <div>\n",
              " <p class=\"inner-text first-item\" id=\"first\">\n",
              "                 Happy PinkWink.\n",
              "                 <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
              " </p>\n",
              " <p class=\"inner-text second-item\">\n",
              "                 Happy Data Science.\n",
              "                 <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
              " </p>\n",
              " </div>\n",
              " <p class=\"outer-text first-item\" id=\"second\">\n",
              " <b>\n",
              "                 Data Science is funny.\n",
              "             </b>\n",
              " </p>\n",
              " <p class=\"outer-text\">\n",
              " <b>\n",
              "                 All I need is Love.\n",
              "             </b>\n",
              " </p>\n",
              " </body>, '\\n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPuEPMGtC5cL"
      },
      "source": [
        "- html 파일의 body만 뽑는 법\n",
        "\n",
        "    1. list로 선언해서 안의 내용부터 출력하기\n",
        "    2. soup.body"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YshbOfvhC5cM",
        "outputId": "56e330d4-e8d2-4cb1-b412-d512552ed8cd"
      },
      "source": [
        "body = list(html.children)[3] # 바디만 따로 담을래\n",
        "body"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<body>\n",
              "<div>\n",
              "<p class=\"inner-text first-item\" id=\"first\">\n",
              "                Happy PinkWink.\n",
              "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
              "</p>\n",
              "<p class=\"inner-text second-item\">\n",
              "                Happy Data Science.\n",
              "                <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
              "</p>\n",
              "</div>\n",
              "<p class=\"outer-text first-item\" id=\"second\">\n",
              "<b>\n",
              "                Data Science is funny.\n",
              "            </b>\n",
              "</p>\n",
              "<p class=\"outer-text\">\n",
              "<b>\n",
              "                All I need is Love.\n",
              "            </b>\n",
              "</p>\n",
              "</body>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cz7DrtvNC5cN"
      },
      "source": [
        "이렇게도 body를 보여줄 수 있어요! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YFtuaprC5cN",
        "outputId": "9be9796a-c1d6-454e-a422-5ff675a8c62a"
      },
      "source": [
        "soup.body # 바로 body 보여줘"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<body>\n",
              "<div>\n",
              "<p class=\"inner-text first-item\" id=\"first\">\n",
              "                Happy PinkWink.\n",
              "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
              "</p>\n",
              "<p class=\"inner-text second-item\">\n",
              "                Happy Data Science.\n",
              "                <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
              "</p>\n",
              "</div>\n",
              "<p class=\"outer-text first-item\" id=\"second\">\n",
              "<b>\n",
              "                Data Science is funny.\n",
              "            </b>\n",
              "</p>\n",
              "<p class=\"outer-text\">\n",
              "<b>\n",
              "                All I need is Love.\n",
              "            </b>\n",
              "</p>\n",
              "</body>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uIkBzvYC5cO"
      },
      "source": [
        "그 다음은 실제 크롤링할 때 정말 유용하게 쓰이는 함수인데요, 바로 **find_all()**입니다. 이것은 괄호 안에 적힌 태그를 모두 가져와주는 기능을 수행해요. 반면에 **find()**는 제일 처음 태그 하나만 가져옵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nuPNFHYC5cQ",
        "outputId": "c555fdae-5ada-4ca5-c239-d0ebda249dee"
      },
      "source": [
        "soup.find_all('p')   # p 태그를 모두 찾아라!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<p class=\"inner-text first-item\" id=\"first\">\n",
              "                 Happy PinkWink.\n",
              "                 <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
              " </p>, <p class=\"inner-text second-item\">\n",
              "                 Happy Data Science.\n",
              "                 <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
              " </p>, <p class=\"outer-text first-item\" id=\"second\">\n",
              " <b>\n",
              "                 Data Science is funny.\n",
              "             </b>\n",
              " </p>, <p class=\"outer-text\">\n",
              " <b>\n",
              "                 All I need is Love.\n",
              "             </b>\n",
              " </p>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1wTwQvBC5cS",
        "outputId": "fe3f1323-e3a1-478d-b276-584f19382524"
      },
      "source": [
        "soup.find_all('p', class_='outer-text')  # p 중 class가 outer-text인 태그만 모두 가져와라 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<p class=\"outer-text first-item\" id=\"second\">\n",
              " <b>\n",
              "                 Data Science is funny.\n",
              "             </b>\n",
              " </p>, <p class=\"outer-text\">\n",
              " <b>\n",
              "                 All I need is Love.\n",
              "             </b>\n",
              " </p>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-y2FvxEC5cS"
      },
      "source": [
        "CSS에서 id와 class를 배웠죠? class 명으로 태그를 가져오는 것도 가능합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YePqUkk0C5cT",
        "outputId": "16b01b27-49bc-4a40-c963-4afd9109d1f0"
      },
      "source": [
        "soup.find_all(class_='outer-text') # 이렇게 찾는 것도 가능"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<p class=\"outer-text first-item\" id=\"second\">\n",
              " <b>\n",
              "                 Data Science is funny.\n",
              "             </b>\n",
              " </p>, <p class=\"outer-text\">\n",
              " <b>\n",
              "                 All I need is Love.\n",
              "             </b>\n",
              " </p>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZR_ox-toC5cT",
        "outputId": "6755b742-44b7-44ee-c617-39212af603ae"
      },
      "source": [
        "soup.find_all(id=\"first\")   #id가 first인 것을 찾아라 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<p class=\"inner-text first-item\" id=\"first\">\n",
              "                 Happy PinkWink.\n",
              "                 <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
              " </p>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnZ6Y4-7C5cU",
        "outputId": "2e548ea0-895f-47ba-94fe-60ea934deed6"
      },
      "source": [
        "soup.find('p') # p 제일 앞의 것을 찾아라"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<p class=\"inner-text first-item\" id=\"first\">\n",
              "                Happy PinkWink.\n",
              "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
              "</p>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35P5N_92C5cU"
      },
      "source": [
        "아래와 같이 head만 가져올 수 있는데요, .next_sibling을 사용해서 그 다음의 태그를 가져올 수 있어요. 두번 쓸 수도 있고요."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kzut_BPLC5cV",
        "outputId": "e9a9841b-08bb-4004-9c8a-985ba53e4f2e"
      },
      "source": [
        "soup.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<title>Very Simple HTML Code by PinkWink</title>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mJGf7E8yC5cW",
        "outputId": "9016efe0-7358-4354-ed58-0b84f18a5607"
      },
      "source": [
        "soup.head.next_sibling # soup.head의 다음 애"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRpAZwO1C5cW",
        "outputId": "8c736a0b-bc52-4631-fb4f-e8a7670ccd04"
      },
      "source": [
        "soup.head.next_sibling.next_sibling # soup.head의 다음 다음 애"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<body>\n",
              "<div>\n",
              "<p class=\"inner-text first-item\" id=\"first\">\n",
              "                Happy PinkWink.\n",
              "                <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
              "</p>\n",
              "<p class=\"inner-text second-item\">\n",
              "                Happy Data Science.\n",
              "                <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
              "</p>\n",
              "</div>\n",
              "<p class=\"outer-text first-item\" id=\"second\">\n",
              "<b>\n",
              "                Data Science is funny.\n",
              "            </b>\n",
              "</p>\n",
              "<p class=\"outer-text\">\n",
              "<b>\n",
              "                All I need is Love.\n",
              "            </b>\n",
              "</p>\n",
              "</body>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6DYlUyYC5cX"
      },
      "source": [
        "이제는 html의 텍스트 정보들을 추출하는 방법에 대해 알아볼게요. 우선 p 태그를 모두 가져와 봅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyvdwhotC5cX",
        "outputId": "bc771557-5dfa-4b59-d0cd-d027a002b82b"
      },
      "source": [
        "soup.find_all('p')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<p class=\"inner-text first-item\" id=\"first\">\n",
              "                 Happy PinkWink.\n",
              "                 <a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>\n",
              " </p>, <p class=\"inner-text second-item\">\n",
              "                 Happy Data Science.\n",
              "                 <a href=\"https://www.python.org\" id=\"py-link\">Python</a>\n",
              " </p>, <p class=\"outer-text first-item\" id=\"second\">\n",
              " <b>\n",
              "                 Data Science is funny.\n",
              "             </b>\n",
              " </p>, <p class=\"outer-text\">\n",
              " <b>\n",
              "                 All I need is Love.\n",
              "             </b>\n",
              " </p>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q12k8kb1C5cX"
      },
      "source": [
        "이렇게 find_all 함수를 쓰게 되면 리스트 형태로 도출이 됩니다. 만약 안에 있는 Happy PinkWink.,  Happy Data Science., Data Science is funny.,All I need is Love.라는 텍스트들만 가져오고 싶다면 어떻게 해야 할까요? 그 때에는 **.get_text()**를 쓰면 됩니다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqr0bPCRC5cY",
        "outputId": "889a3d0d-0c73-436b-c672-1058036bf9df"
      },
      "source": [
        "for each_tag in soup.find_all('p'): #리스트이기에 가능 \n",
        "    print(each_tag.get_text())  # 태그 안의 텍스트만 가져와"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "                Happy PinkWink.\n",
            "                PinkWink\n",
            "\n",
            "\n",
            "                Happy Data Science.\n",
            "                Python\n",
            "\n",
            "\n",
            "\n",
            "                Data Science is funny.\n",
            "            \n",
            "\n",
            "\n",
            "\n",
            "                All I need is Love.\n",
            "            \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4zkd6eZUC5cZ",
        "outputId": "18f83c4d-b89a-4dfc-cf6f-f08963c08e0c"
      },
      "source": [
        "body.get_text()  # 태그가 있는 자리는 줄바꿈이 되고 전체 텍스트를 보여준다"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n\\n\\n                Happy PinkWink.\\n                PinkWink\\n\\n\\n                Happy Data Science.\\n                Python\\n\\n\\n\\n\\n                Data Science is funny.\\n            \\n\\n\\n\\n                All I need is Love.\\n            \\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PY94I94CC5cZ"
      },
      "source": [
        "이번에는 anchor를 가져와 볼게요. 여기에 있는 링크들만 따로 뽑으려면 어떻게 해야 할까요? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5UZ3qJrC5ca",
        "outputId": "35e56f1b-1b17-4e7b-ef3b-214ef0eae788"
      },
      "source": [
        "links = soup.find_all('a')\n",
        "links"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<a href=\"http://www.pinkwink.kr\" id=\"pw-link\">PinkWink</a>,\n",
              " <a href=\"https://www.python.org\" id=\"py-link\">Python</a>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBfPoTEPC5cb",
        "outputId": "cf1eccd8-dee6-4cc0-c13b-4b40907c0933"
      },
      "source": [
        "for each in links: \n",
        "    href = each['href'] #href만 가져와라 \n",
        "    text = each.string\n",
        "    print(text + ' -> ' + href)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PinkWink -> http://www.pinkwink.kr\n",
            "Python -> https://www.python.org\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESenmqwSC5cc"
      },
      "source": [
        "### 3. urllib 라이브러리를 이용해 웹 크롤링하기 \n",
        "\n",
        "이제 앞서 배운 BeautifulSoup 모듈과 urllib 라이브러리를 활용해 실제 사이트에서 웹을 크롤링해봅시다. 네이버 증권 국내증시에서 오늘의 코스피를 가져와 볼게요. \n",
        "\n",
        "우선 크롬의 개발자 도구를 활용하면 내가 가져오고자 하는 텍스트의 태그와 아이디, 클라스를 무척 쉽게 알 수 있어요. 교재 136-138쪽을 보시면 아실 수 있습니다. 혹은 인터넷을 사용해도 되구요.\n",
        "\n",
        "- urllib 라이브러리란 ?\n",
        "urllib은 URL 처리에 관련된 모듈을 모아 놓은 패키지입니다. urllib에 있는 request 모듈을 가져오고, 그 안의 함수를 사용할거에요. urllib.request.urlopen은 URL을 여는 함수인데 URL 열기에 성공하면 response.status의 값이 200이 나옵니다. 이 200은 HTTP 상태 코드이며 웹 서버가 요청을 제대로 처리했다는 뜻입니다. [더 자세한 내용](https://docs.python.org/3/library/urllib.request.html#module-urllib.request)\n",
        "\n",
        "- 크롬 개발자 도구란?\n",
        "구글에서 만든 웹브라우저인 크롬에는 개발을 도와주는 다양한 도구가 기본적으로 제공됩니다. [크롬 개발자 도구 사용법 참고](https://mainia.tistory.com/2393)\n",
        "\n",
        "\n",
        "- [네이버 증권 국내증시](https://finance.naver.com/sise/)\n",
        "\n",
        "코스피를 크롬 개발자 도구로 찾아보니까 <span>에 대한 태그들을 가져와야 겠네요. 그리고 KOSPI_now id를 가지고 있어요. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rDyn3JkZC5cd",
        "outputId": "3fbc356a-2f5c-4637-82f1-59d74960a8ff"
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "res = urlopen('https://finance.naver.com/sise/') # url 넣기\n",
        "print(res.status) # 200이 나오면 성공~\n",
        "soup = BeautifulSoup(res, \"html.parser\") # 객체 생성\n",
        "\n",
        "data = soup.find_all('span', class_='num') # 원하는 태크를 이용해 찾기\n",
        "print(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n",
            "[<span class=\"num num2\" id=\"KOSPI_now\">3,301.89</span>, <span class=\"num \" id=\"KOSDAQ_now\">1,017.91</span>, <span class=\"num num2\" id=\"KPI200_now\">439.98</span>]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpC5iiaeC5ce"
      },
      "source": [
        "data의 형태가 리스트인 것을 아시겠나요?! 코스피만 가져오려면 가장 첫 항목만 가져오면 되겠죠? 출력해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPlNZdiMC5ce",
        "outputId": "4db773a3-0b9a-4372-8866-641c320d5eef"
      },
      "source": [
        "kospi = data[0]\n",
        "kospi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<span class=\"num num2\" id=\"KOSPI_now\">3,301.89</span>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "2Bi4SI0JC5ce",
        "outputId": "948aa925-4a9d-4987-a0af-16ef937a411a"
      },
      "source": [
        "kospi.get_text()  # 문자만 가져와라 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'3,301.89'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RcPHjhuC5cg"
      },
      "source": [
        "get_text()를 이용해 코스피만 딱 가져왔네요 :)\n",
        "\n",
        "### 4. 뉴스 기사 타이틀 크롤링 \n",
        "\n",
        "이번에는 뉴스 기사 타이틀 크롤링하는 것에 대해 알아보려고 해요. 한국일보의 사회 면의 1페이지부터 5페이지까지의 뉴스 타이틀만 가져와볼겁니다.\n",
        "\n",
        "- [한국일보 사회](https://www.hankookilbo.com/News/Society/HC01)\n",
        "\n",
        "우선 필요한 모듈들을 import 해줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9x3Q7P39C5ch"
      },
      "source": [
        "from urllib.request import urlopen # request 모듈에서 urlopen import 할게~\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "url = 'https://www.hankookilbo.com/News/Society/HC01'\n",
        "page = urlopen(url)\n",
        "\n",
        "soup = BeautifulSoup(page, \"html.parser\")\n",
        "\n",
        "#print(soup.prettify())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSvNcT41C5ch"
      },
      "source": [
        "soup의 내용을 그냥 print하면 내용이 엄청 많아요. 저희가 찾고자하는 타이틀이 어떤 태그와 클라스를 가지는지 찾아봅시다. 아까 알려드린 구글 개발자 도구를 사용해보세요!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEtVO-0SC5ch",
        "outputId": "8f3a2243-be4e-4a02-e72f-6ef0637a115b"
      },
      "source": [
        "title = soup.find_all('h3')\n",
        "titles=[]\n",
        "\n",
        "for n in title:\n",
        "    a = n.get_text()\n",
        "    titles.append(a)\n",
        "\n",
        "print(titles)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\"쿠팡이츠 약관은 불공정\"… 자영업단체, 공정위에 심사 청구', \"실종경보문자 '효자' 15분만에 치매노인 찾았다...수원 27분 기록 깨\", '\\'성희롱 논란\\' 박나래 무혐의 결론… 경찰 \"음란행위 아냐\"', '불법 도박사이트 운영하며 수도권 아파트 3채 사들인 일당', \"사상 최대 1조 4700억 '대포통장' 유통 조직 무더기 검거\", '수험생에 \"맘에 든다\" 연락한 수능 감독 교사… 법원 \"징계 정당\"', '광주에 공공 어린이 재활 의료센터 설립', '분당 서현고 김휘성군 끝내 숨진 채 발견... \"타살 흔적 없어\"', \"'의경 아들' 함정 배치 특혜 의혹 해경 함장, 숨진 채 발견\", '돌아온 무지개 행렬... 코로나 속 서울 도심 퀴어축제']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUlrMbwHC5ci"
      },
      "source": [
        "간혹 제목 리스트를 보면 \\xa0와 같은 이상한 문자들이 섞여 나올 때가 있습니다. 이것들은 제목이 아니니 처리해줘야겠죠? 이럴 때 사용하는 것이 바로 **정규표현식**입니다. 이번 주차를 다 공부하고 나면 제목만 쏙쏙 뽑아낼 수 있을거에요. 더 정확한 예시는 첨부한 구글 드라이브의 파일들과 예시를 살펴봅시다!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGBihF7GC5cj"
      },
      "source": [
        "### 5. 정규표현식\n",
        "정규 표현식(Regular Expressions)은 복잡한 문자열을 처리할 때 사용하는 기법으로, 파이썬만의 고유 문법이 아니라 문자열을 처리하는 모든 곳에서 사용해요. 기초 문법 할 때는 다루지 않았는데요, 그만큼 초보들이 배우기에는 어려울 수 있어요. 하지만 우리는 때가 되었으니! 정규표현식에 대해 배워봅시다.\n",
        "\n",
        "[점프 투 파이썬 7장 정규표현식](https://wikidocs.net/1669) - 7장을 모두 숙지하시면 됩니다.\n",
        "\n",
        "위를 학습한 후, **구글 드라이브의 regularexpression.html**을 학습하세요!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luFwKOPxC5cj",
        "outputId": "7405e34e-2163-4c06-d882-2c96116dd9f7"
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "import urllib.request # 403 Forbidden 오류해결\n",
        "headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "res = urllib.request.Request('https://news.naver.com/', headers =headers)\n",
        "page = urlopen(res).read()\n",
        "soup = BeautifulSoup(page, \"html.parser\")\n",
        "\n",
        "data = soup.find_all('div', class_='hdline_article_tit')\n",
        "alist=[]\n",
        "for title in data:\n",
        "    a= title.get_text()\n",
        "    alist.append(a)\n",
        "    \n",
        "print(alist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\n\\n                                        자영업자 입 틀어막은 쿠팡이츠 불공정약관, ‘새우튀김 갑질’ 부추겼다\\n                                    \\n', '\\n\\n                                        반도체·배터리·백신 ‘국가전략기술’로…수출 6천억 달러 돌파 지원\\n                                    \\n', '\\n\\n                                        갑자기 차도 뛰어든 아이…\"민식이법 무죄\" 선고 이유\\n                                    \\n', '\\n\\n                                        [속보] 정부 \"올해 성장률 목표 4.2%로 조정…소비진작책 도입\"\\n                                    \\n', '\\n\\n                                        \\'성추행 사망\\' 女중사 부모 \"군 수사 한계…국정조사 해야\"\\n                                    \\n']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pAtcTYwC5ck",
        "outputId": "61db7f19-5724-4718-f1f5-b93f2b6694ca"
      },
      "source": [
        "from urllib.request import urlopen\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "\n",
        "import urllib.request # 403 Forbidden 오류해결\n",
        "headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "res = urllib.request.Request('https://news.naver.com/', headers =headers)\n",
        "page = urlopen(res).read()\n",
        "soup = BeautifulSoup(page, \"html.parser\")\n",
        "\n",
        "data = soup.find_all('div', class_='hdline_article_tit')\n",
        "alist=[]\n",
        "for title in data:\n",
        "    a= re.sub('[\\\\n]','',title.get_text())\n",
        "    b= re.sub(\"\\s\\s\\s\\s\\s\\s\\s\\s\",'', a)\n",
        "    alist.append(b)\n",
        "    \n",
        "print(alist)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['자영업자 입 틀어막은 쿠팡이츠 불공정약관, ‘새우튀김 갑질’ 부추겼다    ', '반도체·배터리·백신 ‘국가전략기술’로…수출 6천억 달러 돌파 지원    ', '갑자기 차도 뛰어든 아이…\"민식이법 무죄\" 선고 이유    ', '[속보] 정부 \"올해 성장률 목표 4.2%로 조정…소비진작책 도입\"    ', '\\'성추행 사망\\' 女중사 부모 \"군 수사 한계…국정조사 해야\"    ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNgGZzpoC5ck"
      },
      "source": [
        "정규표현식으로 타이틀을 정리해주니 말끔하게 헤드라인 기사 제목만 뽑혔습니다. \"어? 그런데 상견례에 보이는 \\는 안 없어진거 아닌가요?\" 하실 수 있겠지만, 리스트의 요소를 나타낼 때 사용하는 작은 따옴표와 기사 제목의 작은 따옴표를 구분하기 위해 써준거라고 보시면 될거 같아요. 출력해보면 원래대로 나온답니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs_9EW9fC5cm"
      },
      "source": [
        "### 6. openpyxl 모듈로 웹 크롤링 자료 저장, 읽기 \n",
        "\n",
        "크롤링 했다면 그 결과를 담아야 나중에도 또 쓸 수 있겠죠? 후에 판다스에 연결해서 엑셀을 읽어낼 수도 있구요. 이렇게 엑셀에 담기 위해 필요한 모듈은 openpyxl이라는 것인데요, 아래 코드를 한번만 이해한다면 계속해서 활용하실 수 있을 거에요.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6D1JtbFC5cn"
      },
      "source": [
        "# 크롤링 데이터로 엑셀파일 만들기 \n",
        "\n",
        "import openpyxl\n",
        "\n",
        "excel_file = openpyxl.Workbook()\n",
        "excel_file.remove(excel_file.active)\n",
        "excel_sheet = excel_file.create_sheet('안녕 시트')  # sheet 이름 작성 \n",
        "\n",
        "excel_sheet.column_dimensions['B'].width = 150 # column B 크기 정하기 \n",
        "\n",
        "for index in range(9):\n",
        "    excel_sheet.append([index, '안녕']) # 엑셀파일에서 이게 어떻게 구현됐을까요? \n",
        "\n",
        "cell_A1 = excel_sheet['A1']\n",
        "cell_A1.alignment = openpyxl.styles.Alignment(horizontal=\"center\")\n",
        "\n",
        "excel_file.save('test.xlsx')  # 엑셀 파일 이름 설정\n",
        "excel_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDGYiTmPC5co"
      },
      "source": [
        "파일이 저장된 폴더에 가보세요. 그렇다면 test.xlsx 파일이 만들어져 있을 것이랍니다! \n",
        "\n",
        "우리 앞에서 한국일보 타이틀을 추출한 것을 엑셀에다 담아볼까요? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNpH5g8rC5co"
      },
      "source": [
        "from urllib.request import urlopen \n",
        "from bs4 import BeautifulSoup\n",
        "import openpyxl\n",
        "\n",
        "excel_file = openpyxl.Workbook()\n",
        "excel_file.remove(excel_file.active)\n",
        "excel_sheet = excel_file.create_sheet('헤드라인')  # sheet 이름 작성 \n",
        "excel_sheet.column_dimensions['B'].width = 100   # 컬럼 크기 정하기 \n",
        "\n",
        "excel_sheet.append(['번호','제목']) #sheet에 표제목 넣기 \n",
        " \n",
        "import urllib.request # 403 Forbidden 오류해결\n",
        "headers = {'User-Agent': 'Mozilla/5.0'}\n",
        "\n",
        "res = urllib.request.Request('https://news.naver.com/', headers =headers)\n",
        "page = urlopen(res).read()\n",
        "soup = BeautifulSoup(page, \"html.parser\")\n",
        "\n",
        "num = 0\n",
        "data = soup.find_all('div', class_='hdline_article_tit')   # 각 타이틀에서 div 중 class가 hdline_article_tit인 것 가져오기 \n",
        "for title in data: \n",
        "    a= re.sub('[\\\\n]','',title.get_text())\n",
        "    b= re.sub(\"\\s\\s\\s\\s\\s\\s\\s\\s\",'', a)\n",
        "    num += 1\n",
        "    excel_sheet.append([num, b])  # 타이틀 개수와 타이틀 내용\n",
        "\n",
        "\n",
        "cell_A1 = excel_sheet['A1']\n",
        "cell_A1.alignment = openpyxl.styles.Alignment(horizontal=\"center\")  # A1 양식 center로!\n",
        "cell_B1 = excel_sheet['B1']\n",
        "cell_B1.alignment = openpyxl.styles.Alignment(horizontal=\"center\")  # B1 양식 center로!\n",
        "\n",
        "excel_file.save('네이버 뉴스 헤드라인 타이틀 크롤링.xlsx')\n",
        "excel_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h6Hnf3V2C5cu"
      },
      "source": [
        "### 과제\n",
        "\n",
        "이번주 과제는 정규표현식 관련입니다. 한 번 숙지해놓으면 유용하니 어려워도 힘내봅시다!\n",
        "\n",
        "**과제1: 주민번호 뒷자리를 *로 바꿔서 가려보기** (정규표현식 교안: regularexpression.html)\n",
        "\n",
        "**과제2: 전화번호 뒷자리 *로 바꾸어 가리기** (정규표현식 교안: regularexpression.html)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9OYLao0C5cv"
      },
      "source": [
        "### 공부를 끝내며 \n",
        "\n",
        "벌써 데분 스터디 5주차를 끝냈습니다. 정말 많은 것을 배운 것 같네요. pandas부터 시작해 numpy, matplotlib, seaborn, Folium, BeautifulSoup, urllib 라이브러리, 정규표현식, re 모듈 등등등....! 이제 이것들 하나하나가 무엇을 의미하는지는 아실테고, 더불어 사용하는 방법까지 조금이나마 알게 되었죠?😊\n",
        "\n",
        "다음 주차는 배운 웹 크롤링을 기반으로 시카고의 샌드위치 맛집 크롤링 프로젝트를 하려고 합니다. 더불어 네이버 영화 순위 크롤링도 해보구요. \n",
        "\n",
        "모두 수고 많으셨습니다💖 여러분이 고생한 시간이 모여 여름이 끝자락에는 몰라보게 성장한 자신을 발견할 수 있을거예요. 그러니 조금 더 힘내서 데분 스터디를 끝까지 완주해봅시다 😇\n",
        "\n",
        "질문은 언제나 환영하니 주저말고 부끄러워말고 마음껏 해주세요! 그럼 다음 프로젝트에서 만나요~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6J9JcrxC5cw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}