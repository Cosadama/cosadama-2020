{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"WEEK6-2 교안.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOQYZlJoJc8pNozacxzG/X2"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"AbEM3NrsR3cI","colab_type":"text"},"source":["# 머신러닝 맛보기  \n","- 일자: 2020/08/23\n","- 작성자: 김보겸\n","- 참고자료: 파이썬으로 데이터 주무르기(민형기), Intro to DS SPRINGRUSH by 박하람  \n","\n","안녕하세요 여러분! 이번에는 머신러닝에 대해서 진짜 사아알짝 맛만 보는 시간을 가져볼까합니다. 교안을 보다보면 벡터도 나오고, 선형대수도 나오고 해서 멘붕이 오시겠지만...😇 그걸 전부 다 알 필요는 없습니다! 알고리즘 모델을 만들 때 수학이 필요한건데, 저희는 만들어진 모델을 가져다 쓰기만 할거거든요. 그냥 이런게 있구나~ 정도만 알면 됩니다 😚"]},{"cell_type":"markdown","metadata":{"id":"7SVQV8BtUDqf","colab_type":"text"},"source":["## Naive Bayes Classifier의 이해 - 영문  \n","머신러닝에는 지도학습과 비지도학습이 있는데요, 이 나이브 베이즈 분류기는 지도학습에 속합니다. 컴퓨터를 학습시킬 때 데이터에 대한 레이블이 있기 때문에(정답이 있다!) '지도'(supervised)학습이라 부릅니다. \n","\n","더 자세히 알고 싶다면 아래 링크를 참고해주세요!  \n","[머신러닝 종류](https://www.playsw.or.kr/artificial/view/playswtv/672?currentTab=ai_data_video&path=artificial)\n","\n","머신러닝은 기본적으로 어떠한 알고리즘을 만들기 위해 학습시킬 train data와 이 train data를 통해 학습한 알고리즘으로 새롭게 예측해볼 test data를 요구합니다. 여기에서도 train을 통해 알고리즘을 학습시키고 이를 새로운 test data를 넣어 예측해볼 겁니다."]},{"cell_type":"code","metadata":{"id":"Coe8fh_yRzgo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598236541778,"user_tz":-540,"elapsed":76648,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"9fbba938-341a-46ff-e3e0-1522ea112afa"},"source":["# 자연어처리에 필요한 모듈들을 깔아줍시다\n","!apt-get update \n","!apt-get install g++ openjdk-8-jdk python-dev python3-dev \n","!pip3 install JPype1-py3 \n","!pip3 install konlpy \n","!JAVA_HOME=\"C:\\Program Files\\Java\\jdk-13.0.2\""],"execution_count":1,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 2,586 B/88.7\r                                                                               \rGet:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n","\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 25.8 kB/88.7\r0% [Connecting to archive.ubuntu.com (91.189.88.142)] [1 InRelease 46.0 kB/88.7\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [1 InRelease 46.0 kB/88.7 k\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rIgn:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:4 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","\r0% [2 InRelease gpgv 3,626 B] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:5 http://archive.ubuntu.com/ubuntu bionic InRelease\n","Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [697 B]\n","Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","Get:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n","Get:12 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [9,834 B]\n","Get:13 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [101 kB]\n","Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [1,043 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","Get:16 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [890 kB]\n","Ign:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages\n","Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [255 kB]\n","Get:19 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,857 kB]\n","Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,417 kB]\n","Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,341 kB]\n","Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [117 kB]\n","Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [27.4 kB]\n","Get:24 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [896 kB]\n","Fetched 8,227 kB in 3s (2,434 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","python-dev is already the newest version (2.7.15~rc1-1).\n","g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n","g++ set to manually installed.\n","python3-dev is already the newest version (3.6.7-1~18.04).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-440\n","Use 'apt autoremove' to remove it.\n","The following additional packages will be installed:\n","  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n","  libatk-wrapper-java-jni libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n","  openjdk-8-jre-headless x11-utils\n","Suggested packages:\n","  openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin libnss-mdns\n","  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n","  fonts-wqy-zenhei fonts-indic mesa-utils\n","The following NEW packages will be installed:\n","  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n","  libatk-wrapper-java-jni libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n","  openjdk-8-jre openjdk-8-jre-headless x11-utils\n","0 upgraded, 10 newly installed, 0 to remove and 60 not upgraded.\n","Need to get 40.7 MB of archives.\n","After this operation, 153 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u265-b01-0ubuntu2~18.04 [27.5 MB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u265-b01-0ubuntu2~18.04 [69.6 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u265-b01-0ubuntu2~18.04 [8,262 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u265-b01-0ubuntu2~18.04 [1,610 kB]\n","Fetched 40.7 MB in 2s (17.9 MB/s)\n","Selecting previously unselected package libxxf86dga1:amd64.\n","(Reading database ... 144487 files and directories currently installed.)\n","Preparing to unpack .../0-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n","Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n","Selecting previously unselected package fonts-dejavu-core.\n","Preparing to unpack .../1-fonts-dejavu-core_2.37-1_all.deb ...\n","Unpacking fonts-dejavu-core (2.37-1) ...\n","Selecting previously unselected package fonts-dejavu-extra.\n","Preparing to unpack .../2-fonts-dejavu-extra_2.37-1_all.deb ...\n","Unpacking fonts-dejavu-extra (2.37-1) ...\n","Selecting previously unselected package x11-utils.\n","Preparing to unpack .../3-x11-utils_7.7+3build1_amd64.deb ...\n","Unpacking x11-utils (7.7+3build1) ...\n","Selecting previously unselected package libatk-wrapper-java.\n","Preparing to unpack .../4-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n","Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n","Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n","Preparing to unpack .../5-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n","Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n","Selecting previously unselected package openjdk-8-jre-headless:amd64.\n","Preparing to unpack .../6-openjdk-8-jre-headless_8u265-b01-0ubuntu2~18.04_amd64.deb ...\n","Unpacking openjdk-8-jre-headless:amd64 (8u265-b01-0ubuntu2~18.04) ...\n","Selecting previously unselected package openjdk-8-jre:amd64.\n","Preparing to unpack .../7-openjdk-8-jre_8u265-b01-0ubuntu2~18.04_amd64.deb ...\n","Unpacking openjdk-8-jre:amd64 (8u265-b01-0ubuntu2~18.04) ...\n","Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n","Preparing to unpack .../8-openjdk-8-jdk-headless_8u265-b01-0ubuntu2~18.04_amd64.deb ...\n","Unpacking openjdk-8-jdk-headless:amd64 (8u265-b01-0ubuntu2~18.04) ...\n","Selecting previously unselected package openjdk-8-jdk:amd64.\n","Preparing to unpack .../9-openjdk-8-jdk_8u265-b01-0ubuntu2~18.04_amd64.deb ...\n","Unpacking openjdk-8-jdk:amd64 (8u265-b01-0ubuntu2~18.04) ...\n","Setting up fonts-dejavu-core (2.37-1) ...\n","Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n","Setting up fonts-dejavu-extra (2.37-1) ...\n","Setting up openjdk-8-jre-headless:amd64 (8u265-b01-0ubuntu2~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n","Setting up openjdk-8-jdk-headless:amd64 (8u265-b01-0ubuntu2~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n","Setting up x11-utils (7.7+3build1) ...\n","Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n","Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n","Setting up openjdk-8-jre:amd64 (8u265-b01-0ubuntu2~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n","Setting up openjdk-8-jdk:amd64 (8u265-b01-0ubuntu2~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Collecting JPype1-py3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/81/63f5e4202c598f362ee4684b41890f993d6e58309c5d90703f570ab85f62/JPype1-py3-0.5.5.4.tar.gz (88kB)\n","\u001b[K     |████████████████████████████████| 92kB 2.6MB/s \n","\u001b[?25hBuilding wheels for collected packages: JPype1-py3\n","  Building wheel for JPype1-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for JPype1-py3: filename=JPype1_py3-0.5.5.4-cp36-cp36m-linux_x86_64.whl size=2678504 sha256=b447d507f93917a5e0429db8dfb6ee33a84c8c1add4b595209dccb0469334ced\n","  Stored in directory: /root/.cache/pip/wheels/52/37/1f/1015d908d12a0e9b239543d031fda0cded9823aa1306939541\n","Successfully built JPype1-py3\n","Installing collected packages: JPype1-py3\n","Successfully installed JPype1-py3-0.5.5.4\n","Collecting konlpy\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n","\u001b[K     |████████████████████████████████| 19.4MB 1.4MB/s \n","\u001b[?25hCollecting JPype1>=0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/f7/a368401e630f0e390dd0e62c39fb928e5b23741b53c2360ee7d376660927/JPype1-1.0.2-cp36-cp36m-manylinux2010_x86_64.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 45.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.5)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n","Collecting beautifulsoup4==4.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n","\u001b[K     |████████████████████████████████| 92kB 11.8MB/s \n","\u001b[?25hCollecting tweepy>=3.7.0\n","  Downloading https://files.pythonhosted.org/packages/bb/7c/99d51f80f3b77b107ebae2634108717362c059a41384a1810d13e2429a81/tweepy-3.9.0-py2.py3-none-any.whl\n","Collecting colorama\n","  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n","Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.2)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.6/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Installing collected packages: JPype1, beautifulsoup4, tweepy, colorama, konlpy\n","  Found existing installation: beautifulsoup4 4.6.3\n","    Uninstalling beautifulsoup4-4.6.3:\n","      Successfully uninstalled beautifulsoup4-4.6.3\n","  Found existing installation: tweepy 3.6.0\n","    Uninstalling tweepy-3.6.0:\n","      Successfully uninstalled tweepy-3.6.0\n","Successfully installed JPype1-1.0.2 beautifulsoup4-4.6.0 colorama-0.4.3 konlpy-0.5.2 tweepy-3.9.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V79SUP2ZUQMH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"executionInfo":{"status":"ok","timestamp":1598236567495,"user_tz":-540,"elapsed":2429,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"92b6c284-9895-4713-a75b-5ce0331829be"},"source":["import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KPJIbqxMUp4Q","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598236574293,"user_tz":-540,"elapsed":665,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}}},"source":["# 연습용 데이터 train \n","train = [('i like you','pos'),\n","         ('i hate you', 'neg'),\n","         ('you like me', 'neg'),\n","         ('i like her',' pos')]"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Gm5EajPvUvB4","colab_type":"text"},"source":["train 변수 안에 있는 모든 단어들을 가져오는 코드를 작성하려고 하는데요. 그에 앞서서 중복되는 단어들을 제거하려고 해요. 저번 시간처럼 set을 활용해봅시다"]},{"cell_type":"code","metadata":{"id":"72DIKuH7Ur-E","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"ok","timestamp":1598236668047,"user_tz":-540,"elapsed":611,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"9e65a868-51cb-4abe-c9e4-3eccfce5789e"},"source":["for sentence in train: \n","  for word in word_tokenize(sentence[0]): \n","    print(word)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["i\n","like\n","you\n","i\n","hate\n","you\n","you\n","like\n","me\n","i\n","like\n","her\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"54FRf9yFVC3f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598236689586,"user_tz":-540,"elapsed":713,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"d36f0d5e-3282-49c7-f509-f6d94af90910"},"source":["all_words = set(word.lower() for sentence in train \n","                for word in word_tokenize(sentence[0]))\n","all_words"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'hate', 'her', 'i', 'like', 'me', 'you'}"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"YV0Rmd_XVPwu","colab_type":"text"},"source":["자~ 이제 모든 단어가 있는 말뭉치(all_words)가 만들어졌어요. 그럼 이 말뭉치를 기준으로 train의 각 문장에 어떤 단어가 있고 어떤 단어가 없는지 검사해보겠습니다"]},{"cell_type":"code","metadata":{"id":"I62YOOIDVIGt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":510},"executionInfo":{"status":"ok","timestamp":1598236781562,"user_tz":-540,"elapsed":681,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"f21b21ba-e41f-403e-b027-ae883db0846a"},"source":["t = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1])\n","          for x in train]\n","t"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[({'hate': False,\n","   'her': False,\n","   'i': True,\n","   'like': True,\n","   'me': False,\n","   'you': True},\n","  'pos'),\n"," ({'hate': True,\n","   'her': False,\n","   'i': True,\n","   'like': False,\n","   'me': False,\n","   'you': True},\n","  'neg'),\n"," ({'hate': False,\n","   'her': False,\n","   'i': False,\n","   'like': True,\n","   'me': True,\n","   'you': True},\n","  'neg'),\n"," ({'hate': False,\n","   'her': True,\n","   'i': True,\n","   'like': True,\n","   'me': False,\n","   'you': False},\n","  ' pos')]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"AcSIaBWPVf8x","colab_type":"text"},"source":["결과를 해석해보면 train의 첫번째 문장에는 hate가 없고, i는 있다는 뜻이에요. 코드가 조금 복잡해서 이해하기 어려울 수 있지만, 대충 무슨 의미인지 파악하기만 됩니다. 자세한건 이후 머신러닝 커리에서 배우면 돼요~ 이것을 활용해 나이브 베이즈 분류기를 동작시키겠습니다."]},{"cell_type":"code","metadata":{"id":"877p9aUvVekd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":140},"executionInfo":{"status":"ok","timestamp":1598236840271,"user_tz":-540,"elapsed":689,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"3d2d7c4a-55a4-4d1b-ed04-ae4c4af4c6ac"},"source":["classifier = nltk.NaiveBayesClassifier.train(t)\n","classifier.show_most_informative_features()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Most Informative Features\n","                      me = False             pos : neg    =      1.5 : 1.0\n","                    hate = False             pos : neg    =      1.5 : 1.0\n","                       i = True              pos : neg    =      1.5 : 1.0\n","                    like = True              pos : neg    =      1.5 : 1.0\n","                     her = False             neg : pos    =      1.1 : 1.0\n","                     you = True              neg : pos    =      1.1 : 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FuLHUiBvVvBQ","colab_type":"text"},"source":["첫번째 문장 hate = False의 의미는 hate가 없을 때, 긍정일 확률이 1.5, 부정일 확률이 1이라는 의미입니다. train 데이터로 학습시켰으니 test 데이터(새로운 데이터)도 이에 기반해서 잘 예측할 수 있는지 확인해보겠습니다."]},{"cell_type":"code","metadata":{"id":"KLwmatoQVs5q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1598236935067,"user_tz":-540,"elapsed":655,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"6aaf6a18-ea5e-42fe-91ed-8e09455ccd83"},"source":["test_sentence = 'i like MeRui'\n","# 위와 같이 말뭉치를 기준으로 어떤 단어가 있고, 또 어떤 단어는 없는지 검사해봅시다\n","test_sent_features = {word.lower(): \n","                      (word in word_tokenize(test_sentence.lower()))\n","                      for word in all_words}\n","\n","test_sent_features"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'hate': False,\n"," 'her': False,\n"," 'i': True,\n"," 'like': True,\n"," 'me': False,\n"," 'you': False}"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"4sXMUynAV3tN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598237019253,"user_tz":-540,"elapsed":773,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"67da427d-1cbc-4077-d535-f4f57390866d"},"source":["# 위 결과를 classify에 넣으면\n","classifier.classify(test_sent_features)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'pos'"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"uOsnDrFNWbk1","colab_type":"text"},"source":["test_sentence의 문장은 긍정을 나타내는 문장이라 잘 판단했네요. 분류기를 가동시킬 문장이 많으면 신뢰성있는 결론을 얻을 것이라 하는데요, 아주 간단하지만 잘 동작한다는 점에서 '나이브' 베이즈 분류기라고 할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"uQQVNpXOWdS4","colab_type":"text"},"source":["## Naive Byes Classifier의 이해 - 한글\n","\n","한글로도 하려면 형태소 분석을 거쳐야 해요. 형태소 분석을 거치지 않을 경우 어떻게 되는지부터 살펴봅시다."]},{"cell_type":"code","metadata":{"id":"7MimAiU9WYkj","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598237067421,"user_tz":-540,"elapsed":2416,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}}},"source":["from konlpy.tag import Okt\n","pos_tagger = Okt()\n","\n","# 연습 데이터\n","train = [('메리가 좋아', 'pos'), \n","         ('고양이도 좋아', 'pos'),\n","         ('난 수업이 지루해', 'neg'),\n","         ('메리는 이쁜 고양이야', 'pos'),\n","         ('난 마치고 메리랑 놀거야', 'pos')]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"eKNfPCzrWj7c","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"ok","timestamp":1598237088093,"user_tz":-540,"elapsed":694,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"e1cb6e21-7f79-4ee0-90c6-c754b76f36d2"},"source":["# train 데이터의 말뭉치 생성\n","all_words = set(word.lower() for sentence in train\n","                        for word in word_tokenize(sentence[0]))\n","all_words"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'고양이도',\n"," '고양이야',\n"," '난',\n"," '놀거야',\n"," '마치고',\n"," '메리가',\n"," '메리는',\n"," '메리랑',\n"," '수업이',\n"," '이쁜',\n"," '좋아',\n"," '지루해'}"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"v8v8sLxQWrSe","colab_type":"text"},"source":["형태소 분석을 하지 않으면 '고양이도'와 '고양이야'가 / '메리가', '메리는', '메리랑'이 각각 다르게 뽑히게 됩니다. 문장을 제대로 분석하려면 명사와 조사로 나뉘어서 뽑혀야 하는데 붙어서 나와버려요. 우선 이 상태에서 분석을 계속 진행해보겠습니다 "]},{"cell_type":"code","metadata":{"id":"sx8xoUOxXRGW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598237269882,"user_tz":-540,"elapsed":707,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"6cfefba5-0142-436b-89b1-412b00499202"},"source":["# 말뭉치를 기준으로 단어의 유무 검사\n","t = [({word: (word in word_tokenize(x[0])) for word in all_words}, x[1])\n","                                                        for x in train]\n","t"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[({'고양이도': False,\n","   '고양이야': False,\n","   '난': False,\n","   '놀거야': False,\n","   '마치고': False,\n","   '메리가': True,\n","   '메리는': False,\n","   '메리랑': False,\n","   '수업이': False,\n","   '이쁜': False,\n","   '좋아': True,\n","   '지루해': False},\n","  'pos'),\n"," ({'고양이도': True,\n","   '고양이야': False,\n","   '난': False,\n","   '놀거야': False,\n","   '마치고': False,\n","   '메리가': False,\n","   '메리는': False,\n","   '메리랑': False,\n","   '수업이': False,\n","   '이쁜': False,\n","   '좋아': True,\n","   '지루해': False},\n","  'pos'),\n"," ({'고양이도': False,\n","   '고양이야': False,\n","   '난': True,\n","   '놀거야': False,\n","   '마치고': False,\n","   '메리가': False,\n","   '메리는': False,\n","   '메리랑': False,\n","   '수업이': True,\n","   '이쁜': False,\n","   '좋아': False,\n","   '지루해': True},\n","  'neg'),\n"," ({'고양이도': False,\n","   '고양이야': True,\n","   '난': False,\n","   '놀거야': False,\n","   '마치고': False,\n","   '메리가': False,\n","   '메리는': True,\n","   '메리랑': False,\n","   '수업이': False,\n","   '이쁜': True,\n","   '좋아': False,\n","   '지루해': False},\n","  'pos'),\n"," ({'고양이도': False,\n","   '고양이야': False,\n","   '난': True,\n","   '놀거야': True,\n","   '마치고': True,\n","   '메리가': False,\n","   '메리는': False,\n","   '메리랑': True,\n","   '수업이': False,\n","   '이쁜': False,\n","   '좋아': False,\n","   '지루해': False},\n","  'pos')]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"QT-VWjrMXYd6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":210},"executionInfo":{"status":"ok","timestamp":1598237352129,"user_tz":-540,"elapsed":701,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"173306c6-b7ed-42f3-afc8-11ff12270c5c"},"source":["# classifier에 검사내용을 넣어 일종의 예측 가이드라인을 만듭니다\n","classifier = nltk.NaiveBayesClassifier.train(t)\n","classifier.show_most_informative_features()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["Most Informative Features\n","                       난 = True              neg : pos    =      2.5 : 1.0\n","                      좋아 = False             neg : pos    =      1.5 : 1.0\n","                    고양이도 = False             neg : pos    =      1.1 : 1.0\n","                      이쁜 = False             neg : pos    =      1.1 : 1.0\n","                     메리는 = False             neg : pos    =      1.1 : 1.0\n","                     메리가 = False             neg : pos    =      1.1 : 1.0\n","                    고양이야 = False             neg : pos    =      1.1 : 1.0\n","                     마치고 = False             neg : pos    =      1.1 : 1.0\n","                     메리랑 = False             neg : pos    =      1.1 : 1.0\n","                     놀거야 = False             neg : pos    =      1.1 : 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"8xioJAeOXywS","colab_type":"text"},"source":["train 내용을 바탕으로 test 데이터를 넣어 분석해봅시다"]},{"cell_type":"code","metadata":{"id":"LrL5el_GXr4N","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"ok","timestamp":1598237398196,"user_tz":-540,"elapsed":707,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"e55950fe-4da3-45dc-b991-a601e191e71d"},"source":["test_sentence = '난 수업이 마치면 메리랑 놀거야'\n","test_sent_features = {word.lower(): \n","                      (word in word_tokenize(test_sentence.lower()))\n","                      for word in all_words}\n","test_sent_features"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'고양이도': False,\n"," '고양이야': False,\n"," '난': True,\n"," '놀거야': True,\n"," '마치고': False,\n"," '메리가': False,\n"," '메리는': False,\n"," '메리랑': True,\n"," '수업이': True,\n"," '이쁜': False,\n"," '좋아': False,\n"," '지루해': False}"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"-IuzaivEX3KJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598237408370,"user_tz":-540,"elapsed":765,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"aedf2545-9412-4943-a42c-4d5792cdf8b4"},"source":["classifier.classify(test_sent_features)"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'neg'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"31q70U84WrXQ","colab_type":"text"},"source":["이런! '난 수업이 마치면 메리랑 놀거야'라는 문장을 부정적인 문장이라고 분석했네요. 자, 이제 형태소 분석의 중요성을 잘 아셨을겁니다"]},{"cell_type":"code","metadata":{"id":"sGKy0JS6WpZ0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598237518015,"user_tz":-540,"elapsed":634,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}}},"source":["def tokenize(doc): \n","  return ['/'.join(t) for t in pos_tagger.pos(doc, norm=True, stem=True)]"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MvQFZeheYYbL","colab_type":"text"},"source":["konlpy를 만든 Lucy Park에 따르면 위의 함수처럼 태그를 붙여주는 것이 유리하다고 해요. tokenize 함수를 사용해서 train 문장을 형태소 분석해보겠습니다.\n","\n","tokenize가 뭔지 잘 모르겠다면, 저번 교안에서 제가 알려드린 내용을 다시 읽어보시면 됩니다!👨‍🏫\n","- 문자열 단위를 토큰(token)이라고 하고 이렇게 문자열을 토큰으로 나누는 작업을 토큰 생성(tokenizing)이라고 하고\n","- 문자열을 토큰으로 분리하는 함수를 토큰 생성 함수(tokenizer)라고 합니다. "]},{"cell_type":"code","metadata":{"id":"lQ5M_8L_YSX4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":105},"executionInfo":{"status":"ok","timestamp":1598237755699,"user_tz":-540,"elapsed":7268,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"90eb0ac7-eaf4-4e98-e526-44e8599d610b"},"source":["train = [('메리가 좋아', 'pos'), \n","         ('고양이도 좋아', 'pos'),\n","         ('난 수업이 지루해', 'neg'),\n","         ('메리는 이쁜 고양이야', 'pos'),\n","         ('난 마치고 메리랑 놀거야', 'pos')] \n","\n","train_docs = [(tokenize(row[0]), row[1]) for row in train]\n","train_docs"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(['메리/Noun', '가/Josa', '좋다/Adjective'], 'pos'),\n"," (['고양이/Noun', '도/Josa', '좋다/Adjective'], 'pos'),\n"," (['난/Noun', '수업/Noun', '이/Josa', '지루하다/Adjective'], 'neg'),\n"," (['메리/Noun', '는/Josa', '이쁘다/Adjective', '고양이/Noun', '야/Josa'], 'pos'),\n"," (['난/Noun', '마치/Noun', '고/Josa', '메리/Noun', '랑/Josa', '놀다/Verb'], 'pos')]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"8N8zVJkaZKx0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":386},"executionInfo":{"status":"ok","timestamp":1598237778605,"user_tz":-540,"elapsed":751,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"bcec6e93-ccb9-4d13-ca91-393cf25a9945"},"source":["# 이 코드를 아래 코드에서는 한 줄로 적어준 겁니다!\n","for d in train_docs: \n","  for t in d[0]: \n","    print(t)"],"execution_count":20,"outputs":[{"output_type":"stream","text":["메리/Noun\n","가/Josa\n","좋다/Adjective\n","고양이/Noun\n","도/Josa\n","좋다/Adjective\n","난/Noun\n","수업/Noun\n","이/Josa\n","지루하다/Adjective\n","메리/Noun\n","는/Josa\n","이쁘다/Adjective\n","고양이/Noun\n","야/Josa\n","난/Noun\n","마치/Noun\n","고/Josa\n","메리/Noun\n","랑/Josa\n","놀다/Verb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HixPNdBKZR-G","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":386},"executionInfo":{"status":"ok","timestamp":1598237784617,"user_tz":-540,"elapsed":709,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"47da9036-9e3f-4f1b-e4d4-38bf47cb5261"},"source":["tokens = [t for d in train_docs for t in d[0]]\n","tokens"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['메리/Noun',\n"," '가/Josa',\n"," '좋다/Adjective',\n"," '고양이/Noun',\n"," '도/Josa',\n"," '좋다/Adjective',\n"," '난/Noun',\n"," '수업/Noun',\n"," '이/Josa',\n"," '지루하다/Adjective',\n"," '메리/Noun',\n"," '는/Josa',\n"," '이쁘다/Adjective',\n"," '고양이/Noun',\n"," '야/Josa',\n"," '난/Noun',\n"," '마치/Noun',\n"," '고/Josa',\n"," '메리/Noun',\n"," '랑/Josa',\n"," '놀다/Verb']"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"WC375pEFZa6l","colab_type":"text"},"source":["이렇게 전체 말뭉치(tokens)를 만들었습니다. 아래 함수는 해당 문장에 있는 형태소가 tokens 안에 들어있는지 확인하는 것이에요"]},{"cell_type":"code","metadata":{"id":"2gqlotw4ZTct","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598237842058,"user_tz":-540,"elapsed":628,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}}},"source":["def term_exists(doc): \n","  return {word: (word in set(doc)) for word in tokens}"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"2hIMOIB1Zhfd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1598237847575,"user_tz":-540,"elapsed":730,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"e53ac587-1222-4d1a-b864-b2ee7499fcc2"},"source":["train_xy = [(term_exists(d), c) for d,c in train_docs]\n","train_xy"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[({'가/Josa': True,\n","   '고/Josa': False,\n","   '고양이/Noun': False,\n","   '난/Noun': False,\n","   '놀다/Verb': False,\n","   '는/Josa': False,\n","   '도/Josa': False,\n","   '랑/Josa': False,\n","   '마치/Noun': False,\n","   '메리/Noun': True,\n","   '수업/Noun': False,\n","   '야/Josa': False,\n","   '이/Josa': False,\n","   '이쁘다/Adjective': False,\n","   '좋다/Adjective': True,\n","   '지루하다/Adjective': False},\n","  'pos'),\n"," ({'가/Josa': False,\n","   '고/Josa': False,\n","   '고양이/Noun': True,\n","   '난/Noun': False,\n","   '놀다/Verb': False,\n","   '는/Josa': False,\n","   '도/Josa': True,\n","   '랑/Josa': False,\n","   '마치/Noun': False,\n","   '메리/Noun': False,\n","   '수업/Noun': False,\n","   '야/Josa': False,\n","   '이/Josa': False,\n","   '이쁘다/Adjective': False,\n","   '좋다/Adjective': True,\n","   '지루하다/Adjective': False},\n","  'pos'),\n"," ({'가/Josa': False,\n","   '고/Josa': False,\n","   '고양이/Noun': False,\n","   '난/Noun': True,\n","   '놀다/Verb': False,\n","   '는/Josa': False,\n","   '도/Josa': False,\n","   '랑/Josa': False,\n","   '마치/Noun': False,\n","   '메리/Noun': False,\n","   '수업/Noun': True,\n","   '야/Josa': False,\n","   '이/Josa': True,\n","   '이쁘다/Adjective': False,\n","   '좋다/Adjective': False,\n","   '지루하다/Adjective': True},\n","  'neg'),\n"," ({'가/Josa': False,\n","   '고/Josa': False,\n","   '고양이/Noun': True,\n","   '난/Noun': False,\n","   '놀다/Verb': False,\n","   '는/Josa': True,\n","   '도/Josa': False,\n","   '랑/Josa': False,\n","   '마치/Noun': False,\n","   '메리/Noun': True,\n","   '수업/Noun': False,\n","   '야/Josa': True,\n","   '이/Josa': False,\n","   '이쁘다/Adjective': True,\n","   '좋다/Adjective': False,\n","   '지루하다/Adjective': False},\n","  'pos'),\n"," ({'가/Josa': False,\n","   '고/Josa': True,\n","   '고양이/Noun': False,\n","   '난/Noun': True,\n","   '놀다/Verb': True,\n","   '는/Josa': False,\n","   '도/Josa': False,\n","   '랑/Josa': True,\n","   '마치/Noun': True,\n","   '메리/Noun': True,\n","   '수업/Noun': False,\n","   '야/Josa': False,\n","   '이/Josa': False,\n","   '이쁘다/Adjective': False,\n","   '좋다/Adjective': False,\n","   '지루하다/Adjective': False},\n","  'pos')]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"Sx4f495hZmO1","colab_type":"text"},"source":["변수명이 위에서는 all_words였다가 이번에는 tokens로, t에서 train_xy로 바뀌었을 뿐 원리는 똑같습니다"]},{"cell_type":"code","metadata":{"id":"BMjJd68NZi0Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":210},"executionInfo":{"status":"ok","timestamp":1598238037915,"user_tz":-540,"elapsed":628,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"e5e292ce-9908-4c1c-9e6a-5a5370c138f7"},"source":["classifier = nltk.NaiveBayesClassifier.train(train_xy)\n","classifier.show_most_informative_features()"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Most Informative Features\n","                  난/Noun = True              neg : pos    =      2.5 : 1.0\n","                 메리/Noun = False             neg : pos    =      2.5 : 1.0\n","            좋다/Adjective = False             neg : pos    =      1.5 : 1.0\n","                고양이/Noun = False             neg : pos    =      1.5 : 1.0\n","                  야/Josa = False             neg : pos    =      1.1 : 1.0\n","                 놀다/Verb = False             neg : pos    =      1.1 : 1.0\n","                  랑/Josa = False             neg : pos    =      1.1 : 1.0\n","                  도/Josa = False             neg : pos    =      1.1 : 1.0\n","                  고/Josa = False             neg : pos    =      1.1 : 1.0\n","                 마치/Noun = False             neg : pos    =      1.1 : 1.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"im8hNoquaUou","colab_type":"text"},"source":["자 이제 검사의 조건들이 갖춰졌으니 다시 test_sentence를 가지고 분석을 해봅시다"]},{"cell_type":"code","metadata":{"id":"toF_o8qHaRTY","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"status":"ok","timestamp":1598238076948,"user_tz":-540,"elapsed":780,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"d2c3ea07-1868-4957-fc9b-4c77aab5959d"},"source":["test_sentence = [('난 수업이 마치면 코사다마랑 놀거야')]\n","\n","# 똑같이 형태소 분석 \n","test_docs = pos_tagger.pos(test_sentence[0])\n","test_docs"],"execution_count":25,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('난', 'Noun'),\n"," ('수업', 'Noun'),\n"," ('이', 'Josa'),\n"," ('마치', 'Noun'),\n"," ('면', 'Josa'),\n"," ('코', 'Noun'),\n"," ('사', 'Modifier'),\n"," ('다마', 'Noun'),\n"," ('랑', 'Josa'),\n"," ('놀거야', 'Verb')]"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"3D_EZuhLaazN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":193},"executionInfo":{"status":"ok","timestamp":1598238084752,"user_tz":-540,"elapsed":731,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"bd4b52a7-9779-43aa-8bab-1820dd769631"},"source":["test_sent_features = {word: (word in tokens) for word in test_docs}\n","test_sent_features"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{('난', 'Noun'): False,\n"," ('놀거야', 'Verb'): False,\n"," ('다마', 'Noun'): False,\n"," ('랑', 'Josa'): False,\n"," ('마치', 'Noun'): False,\n"," ('면', 'Josa'): False,\n"," ('사', 'Modifier'): False,\n"," ('수업', 'Noun'): False,\n"," ('이', 'Josa'): False,\n"," ('코', 'Noun'): False}"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"id":"x83rhKbWact_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1598238093552,"user_tz":-540,"elapsed":763,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"bee4e6b6-edff-48d4-b9b5-7a6c5345d599"},"source":["classifier.classify(test_sent_features)"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'pos'"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"ZtvRw1yHafpR","colab_type":"text"},"source":["와우 🙊 이젠 긍정으로 잘 분석되었네요"]},{"cell_type":"markdown","metadata":{"id":"h7Mq8wIvawjs","colab_type":"text"},"source":["## 문장의 유사도 측정하기  \n","많은 문장 혹은 문서들 중에서 유사한 문장을 찾아내는 방법입니다. 어떤 문장을 벡터로 표현할 수 있으면 벡터 간 거리를 구하는 방법으로 문장 간 유사도를 측정할 수 있습니다. 이해가 잘 안가셔도 괜찮습니다. 그냥 이런게 있구나~ 정도로 넘어가시면 됩니당 (사실 저도 정확한 원리까지는 잘 몰라요~ 2학기 머신러닝 커리에서 같이 공부해봅시다 👹)"]},{"cell_type":"code","metadata":{"id":"aN9scHNqae2-","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598238216350,"user_tz":-540,"elapsed":659,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}}},"source":["# 텍스트의 특징을 추출하는 모듈\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","# min_df: 특정 단어가 min_df보다 적은 빈도수가지면 그 단어 피처 제외 \n","vectorizer = CountVectorizer(min_df = 1)"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"moWDxQH6a82r","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598238228102,"user_tz":-540,"elapsed":739,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}}},"source":["# 유사한 문장을 연습용으로 사용해보기\n","# feat. 맞춤법 어떻하죠? \n","contents = ['메리랑 놀러가고 싶지만 바쁜데 어떻하죠?',\n","            '메리는 공원에서 산책하고 노는 것을 싫어해요',\n","            '메리는 공원에서 노는 것도 싫어해요. 이상해요.',\n","            '먼 곳으로 여행을 떠나고 싶은데 너무 바빠서 그러질 못하고 있어요']"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"uPVpDpLha_t1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":404},"executionInfo":{"status":"ok","timestamp":1598238234353,"user_tz":-540,"elapsed":730,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"a0affeea-8455-40c2-c3a2-db7191c65688"},"source":["X = vectorizer.fit_transform(contents)\n","vectorizer.get_feature_names()"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['것도',\n"," '것을',\n"," '곳으로',\n"," '공원에서',\n"," '그러질',\n"," '너무',\n"," '노는',\n"," '놀러가고',\n"," '떠나고',\n"," '메리는',\n"," '메리랑',\n"," '못하고',\n"," '바빠서',\n"," '바쁜데',\n"," '산책하고',\n"," '싫어해요',\n"," '싶은데',\n"," '싶지만',\n"," '어떻하죠',\n"," '여행을',\n"," '이상해요',\n"," '있어요']"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"yixWAFdYbUHI","colab_type":"text"},"source":["어떻게 벡터화되는지는 교재 316쪽의 그림 8-19를 꼭 보고 이해해보기! 이렇게 벡터화하면 '메리는'과 '메리랑'을 다르게 생각되므로 더 한글 문장에 맞춰서 진행해봅시다."]},{"cell_type":"code","metadata":{"id":"fpgOMIgMbBPp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":318},"executionInfo":{"status":"ok","timestamp":1598238325048,"user_tz":-540,"elapsed":673,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"74a52d9f-1a4a-40db-b634-e46570331962"},"source":["from konlpy.tag import Okt \n","okt = Okt()\n","contents_tokens = [okt.morphs(row) for row in contents]\n","contents_tokens"],"execution_count":31,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['메리', '랑', '놀러', '가고', '싶지만', '바쁜데', '어떻하죠', '?'],\n"," ['메리', '는', '공원', '에서', '산책', '하고', '노', '는', '것', '을', '싫어해요'],\n"," ['메리', '는', '공원', '에서', '노', '는', '것', '도', '싫어해요', '.', '이상해요', '.'],\n"," ['먼',\n","  '곳',\n","  '으로',\n","  '여행',\n","  '을',\n","  '떠나고',\n","  '싶은데',\n","  '너무',\n","  '바빠서',\n","  '그러질',\n","  '못',\n","  '하고',\n","  '있어요']]"]},"metadata":{"tags":[]},"execution_count":31}]},{"cell_type":"markdown","metadata":{"id":"f37ycUEobZFC","colab_type":"text"},"source":["이제 자연어 처리 자체는 익숙하죵? '메리는'과 '메리랑'이 '메리','는','메리','랑'으로 잘 나눠집니다. 형태소 분석한 것을 하나의 문장으로 담을거에요. 대신, 각각의 형태소별로 띄어쓰기를 하여 sciket learn의 vectorizer 함수에서 사용하기 편하게 편집할겁니다"]},{"cell_type":"code","metadata":{"id":"ss9-CHP1bXZO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1598238408458,"user_tz":-540,"elapsed":743,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"095ef5b1-516a-4eb3-dda6-59823fe1d03b"},"source":["contents_for_vectorize = []\n","\n","for content in contents_tokens:\n","  sentence =''\n","  for word in content: \n","    sentence = sentence + ' ' + word \n","\n","  contents_for_vectorize.append(sentence)\n","\n","contents_for_vectorize"],"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[' 메리 랑 놀러 가고 싶지만 바쁜데 어떻하죠 ?',\n"," ' 메리 는 공원 에서 산책 하고 노 는 것 을 싫어해요',\n"," ' 메리 는 공원 에서 노 는 것 도 싫어해요 . 이상해요 .',\n"," ' 먼 곳 으로 여행 을 떠나고 싶은데 너무 바빠서 그러질 못 하고 있어요']"]},"metadata":{"tags":[]},"execution_count":32}]},{"cell_type":"code","metadata":{"id":"qxjKWjZhbrvQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598238415023,"user_tz":-540,"elapsed":651,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"5c9c3173-c80f-453d-d5dc-0cb9f6d659a3"},"source":["X = vectorizer.fit_transform(contents_for_vectorize)\n","num_samples, num_features = X.shape \n","num_samples, num_features"],"execution_count":33,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4, 20)"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"code","metadata":{"id":"p3Hhb8nBbtXr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"status":"ok","timestamp":1598238421260,"user_tz":-540,"elapsed":753,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"a7150196-fcdc-48f2-c378-e40d3c5e2d64"},"source":["vectorizer.get_feature_names()"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['가고',\n"," '공원',\n"," '그러질',\n"," '너무',\n"," '놀러',\n"," '떠나고',\n"," '메리',\n"," '바빠서',\n"," '바쁜데',\n"," '산책',\n"," '싫어해요',\n"," '싶은데',\n"," '싶지만',\n"," '어떻하죠',\n"," '에서',\n"," '여행',\n"," '으로',\n"," '이상해요',\n"," '있어요',\n"," '하고']"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"OJn8F4v2bxsH","colab_type":"text"},"source":["말뭉치가 잘 형성되었네요! 1개 이하로 나오는 것은 말뭉치에 왜 넣지 않은지는 앞서 객체 생성할 때 min_df 파라미터를 1로 설정해주었기 때문이에요. 이 리스트를 numpy의 array 형식으로 바꾸어주고, 행과 열을 바꿔서 표시해주려고 합니다. 결과는 318쪽 그림 8-21에 있어요."]},{"cell_type":"code","metadata":{"id":"XuccIlsYbu3f","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"status":"ok","timestamp":1598238449164,"user_tz":-540,"elapsed":624,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"b5585526-ecc0-45c7-9615-f819bded0278"},"source":["X.toarray().transpose()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[1, 0, 0, 0],\n","       [0, 1, 1, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [0, 0, 0, 1],\n","       [1, 1, 1, 0],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [0, 1, 0, 0],\n","       [0, 1, 1, 0],\n","       [0, 0, 0, 1],\n","       [1, 0, 0, 0],\n","       [1, 0, 0, 0],\n","       [0, 1, 1, 0],\n","       [0, 0, 0, 1],\n","       [0, 0, 0, 1],\n","       [0, 0, 1, 0],\n","       [0, 0, 0, 1],\n","       [0, 1, 0, 1]])"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"QDSplAVtb3B_","colab_type":"text"},"source":["transpose는 행과 열을 바꾼 행렬인 전치행렬을 만들라는 함수인데요. 이게 알고보니까 수학 개념이더라고요. 확실히 수학을 알면 코딩도 조금은 쉬워지는 것 같습니다\n","\n","여튼! 이렇게 학습 데이터를 기반으로 말뭉치를 잘 만들어주었으니, 테스트 데이터를 넣어봐야겠지요. 새로운 문장을 동일하게 벡터화해서 각 벡터들 사이의 거리를 구하면 문장 간의 유사도를 측정할 수 있다는 개념이에요."]},{"cell_type":"code","metadata":{"id":"Yfqptw2pb1tm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598238545607,"user_tz":-540,"elapsed":690,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"f227978c-df69-4948-c051-e080d5728f1e"},"source":["new_post = ['메리랑 공원에서 산책하고 놀고 싶어요']\n","new_post_tokens = [okt.morphs(row) for row in new_post]\n","\n","new_post_for_vectorize = []\n","\n","for content in new_post_tokens:\n","  sentence =''\n","  for word in content: \n","    sentence = sentence + ' ' + word\n","\n","  new_post_for_vectorize.append(sentence)\n","\n","new_post_for_vectorize"],"execution_count":36,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[' 메리 랑 공원 에서 산책 하고 놀고 싶어요']"]},"metadata":{"tags":[]},"execution_count":36}]},{"cell_type":"markdown","metadata":{"id":"W0a4k9c0cPrN","colab_type":"text"},"source":["벡터화하기 쉽도록 문장을 잘 가공해주었고, 벡터화를 시켜주면 됩니다."]},{"cell_type":"code","metadata":{"id":"OjBWCFsRcNO-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598238569944,"user_tz":-540,"elapsed":753,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"99e24d3c-c975-4630-d2bb-ce329d19afbc"},"source":["new_post_vec = vectorizer.transform(new_post_for_vectorize)\n","new_post_vec.toarray()"],"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]])"]},"metadata":{"tags":[]},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"Wa4BahRGcfl2","colab_type":"text"},"source":["## 유클리드 거리 유사도\n","자! 그럼 이 상태에서 어떻게 유사도 측정을 하느냐? 크게 두가지 방법이 있는 것 같습니다. 하나는 거리 차이를 이용하는 방법, 다른 하나는 각도 차이를 이용하는 방법이 있어요. 여기에서는 거리 차이를 이용해서 측정하는 방법을 사용하는데요, 정확히는 유클리드 거리 유사도를 사용하여 문장 간의 유사도를 측정해보는 방법입니다. 거리를 기반으로 하면, 특정 좌표 주변과 가까이에 있는 것이 유사도가 높다고 판단하는 것이죠.  \n","\n","[이미지예시](https://d1z1a3q7uy2q8k.cloudfront.net/blog_images/image_5394346701474615621316.png, https://specialscene.tistory.com/48)\n","\n","\n","벡터 a의 길이는 놈(norm)으로 정의하는데요, 이를 구현해주는 코드가 np.linalg.norm()이라고 러프하게 이해하시면 될 듯 합니다..ㅎㅎ 벡터에 대해서 알아보고 싶으면 slack 채널에 mathematics 방으로 오세요. 같이 선형대수를 배워봅시다!\n","\n","[참고: 벡터의 길이](https://datascienceschool.net/view-notebook/dd1680bfbaab414a8d54dc978c6e883a/)"]},{"cell_type":"code","metadata":{"id":"TYm0j6wccTKz","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598238682398,"user_tz":-540,"elapsed":697,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}}},"source":["import scipy as sp \n","\n","def dist_raw(v1, v2):\n","  delta = v1 - v2 \n","  return sp.linalg.norm(delta.toarray())"],"execution_count":38,"outputs":[]},{"cell_type":"code","metadata":{"id":"9U6NZfFlcuom","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1598238691722,"user_tz":-540,"elapsed":659,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"0be536f1-f937-4cb2-8b79-617ab2bbaa3f"},"source":["best_doc = None\n","# 65535가 무슨 의미인지는 모르겠네요... \n","best_dist = 65535 \n","best_i = None \n","\n","for i in range(0, num_samples):\n","  post_vec = X.getrow(i)\n","  d = dist_raw(post_vec, new_post_vec)\n","\n","  # i는 문장 번호, d는 유사도\n","  print('== Post %i with dist=%.2f    : %s' % (i,d,contents[i]))\n","\n","# best_dist가 계속 낮게 수정되는 것! (낮을수록 유사도 높음)\n","  if d < best_dist: \n","    best_dist = d\n","    best_i = i"],"execution_count":39,"outputs":[{"output_type":"stream","text":["== Post 0 with dist=3.00    : 메리랑 놀러가고 싶지만 바쁜데 어떻하죠?\n","== Post 1 with dist=1.00    : 메리는 공원에서 산책하고 노는 것을 싫어해요\n","== Post 2 with dist=2.00    : 메리는 공원에서 노는 것도 싫어해요. 이상해요.\n","== Post 3 with dist=3.46    : 먼 곳으로 여행을 떠나고 싶은데 너무 바빠서 그러질 못하고 있어요\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OnXZhNAHcw52","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1598238698001,"user_tz":-540,"elapsed":677,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"f15ac1ef-3bc1-4bbb-f2fd-2e0dc03820ff"},"source":["print('Best post is %i, dist = %.2f' % (best_i, best_dist))\n","print('-->', new_post)\n","print('---->', contents[best_i])"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Best post is 1, dist = 1.00\n","--> ['메리랑 공원에서 산책하고 놀고 싶어요']\n","----> 메리는 공원에서 산책하고 노는 것을 싫어해요\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nAgNp2nFc0NC","colab_type":"text"},"source":["가장 유사도가 높은 문장이 바로 '메리는 공원에서 산책하고 노는 것을 싫어해요'라는 문장이네요! 의미는 반대나 조합이 비슷해서 유사도를 높게 측정한 듯 합니다."]},{"cell_type":"code","metadata":{"id":"sYGuGmOlcycm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1598238713490,"user_tz":-540,"elapsed":667,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"d0115ca6-545c-4e23-8908-a0cbff5e6e55"},"source":["# contents와 새로운 문장이 벡터화된 결과 \n","\n","for i in range(0, len(contents)):\n","  # 벡터화한 것의 row만 가져와봐라\n","  print(X.getrow(i).toarray())\n","\n","print('------------------')\n","print(new_post_vec.toarray())"],"execution_count":41,"outputs":[{"output_type":"stream","text":["[[1 0 0 0 1 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0]]\n","[[0 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1]]\n","[[0 1 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 1 0 0]]\n","[[0 0 1 1 0 1 0 1 0 0 0 1 0 0 0 1 1 0 1 1]]\n","------------------\n","[[0 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 1]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u_CgMnG_c2Ow","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1598238722208,"user_tz":-540,"elapsed":775,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}}},"source":["def dist_norm(v1, v2): \n","  v1_normalized = v1 / sp.linalg.norm(v1.toarray())\n","  v2_normalized = v2 / sp.linalg.norm(v2.toarray())\n","\n","  delta = v1_normalized - v2_normalized \n","\n","  return sp.linalg.norm(delta.toarray())"],"execution_count":42,"outputs":[]},{"cell_type":"code","metadata":{"id":"gRmqKmhGc4VK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1598238729022,"user_tz":-540,"elapsed":803,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"bda203de-12dc-4804-fbca-eabe084dd62c"},"source":["best_doc = None \n","best_dist = 65535\n","best_i = None \n","\n","for i in range(0, num_samples): \n","  # 앞에서 array로 바꿔줬으니 다시 array로 바꿔줄필요 없음 \n","  post_vec = X.getrow(i)\n","  d = dist_norm(post_vec, new_post_vec)\n","\n","  print(\"== Post %i with dist=%2f   : %s\" % (i,d,contents[i]))\n","\n","  if d < best_dist: \n","    best_dist = d\n","    best_i = i"],"execution_count":43,"outputs":[{"output_type":"stream","text":["== Post 0 with dist=1.278613   : 메리랑 놀러가고 싶지만 바쁜데 어떻하죠?\n","== Post 1 with dist=0.417442   : 메리는 공원에서 산책하고 노는 것을 싫어해요\n","== Post 2 with dist=0.894427   : 메리는 공원에서 노는 것도 싫어해요. 이상해요.\n","== Post 3 with dist=1.304553   : 먼 곳으로 여행을 떠나고 싶은데 너무 바빠서 그러질 못하고 있어요\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UIMem1XZc5_i","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1598238735875,"user_tz":-540,"elapsed":755,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"1d8c3d29-c8ef-4278-8425-dc2d0187863f"},"source":["print('Best post is %i, dist = %.2f' % (best_i, best_dist))\n","print('-->', new_post)\n","print('---->', contents[best_i])"],"execution_count":44,"outputs":[{"output_type":"stream","text":["Best post is 1, dist = 0.42\n","--> ['메리랑 공원에서 산책하고 놀고 싶어요']\n","----> 메리는 공원에서 산책하고 노는 것을 싫어해요\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ePxN1dPwdAZj","colab_type":"text"},"source":["## TF-IDF  \n","tf(term frequency)와 idf(inverse document frequency)는 텍스트 마이닝에서 사용하는 일종의 단어별로 부과하는 가중치입니다. tf는 어떤 단어가 문서 내에서 자주 등장할수록 중요도가 높을 것으로 보는 것이고, idf는 비교하는 모든 문서에 만약 같은 단어가 있다면 이 단어는 핵심 어휘일지는 모르지만 문서 간의 비교에서는 중요한 단어가 아니라는 뜻으로 보는 것이에요. 교재 322쪽에서는 직접 함수를 만들어 예제에 적용해본 결과가 있지만, (이해가 중요할 수도 있겠지만) 이것의 의미를 알고 일단 우리는 적용해서 해석할 수 있기만 하면 돼요! 우리가 사용할 것은 **TF-IDF** 기반의 벡터화이고, 개별 문서에서 자주 나타나는 단어에 높은 가중치를 주되, 모든 문서에서 전반적으로 자주 나타나는 단어에 대해서는 페널티를 주는 방식으로 값을 부여한다고 보면 됩니다\n","\n","정독해보기 [TF-IDF의 개념](https://charsyam.wordpress.com/2017/04/08/%EC%9A%A9%EC%96%B4-%EC%A0%95%EB%A6%AC-%EC%9E%85-%EA%B0%9C%EB%B0%9C%EC%9E%90%EB%A5%BC-%EC%9C%84%ED%95%9C-tf-idf/)"]},{"cell_type":"code","metadata":{"id":"8LvYR_88c7rW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598238791091,"user_tz":-540,"elapsed":871,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"6a7dd729-7779-4f3e-b526-b89ac7130bf4"},"source":["from sklearn.feature_extraction.text import TfidfVectorizer \n","# decode_error은 디코딩 에러 무시한다는 말! \n","vectorizer = TfidfVectorizer(min_df=1, decode_error='ignore')\n","\n","contents_tokens = [okt.morphs(row) for row in contents]\n","\n","contents_for_vectorize = []\n","\n","for content in contents_tokens: \n","  sentence = ''\n","  for word in content: \n","    sentence = sentence + ' ' + word \n","\n","  contents_for_vectorize.append(sentence)\n","\n","X = vectorizer.fit_transform(contents_for_vectorize)\n","num_samples, num_features = X.shape \n","num_samples, num_features"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4, 20)"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"7betBcfKdJIJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":369},"executionInfo":{"status":"ok","timestamp":1598238797000,"user_tz":-540,"elapsed":871,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"471d4b5f-0624-4a8e-f0ab-8db25bcf2353"},"source":["vectorizer.get_feature_names()"],"execution_count":46,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['가고',\n"," '공원',\n"," '그러질',\n"," '너무',\n"," '놀러',\n"," '떠나고',\n"," '메리',\n"," '바빠서',\n"," '바쁜데',\n"," '산책',\n"," '싫어해요',\n"," '싶은데',\n"," '싶지만',\n"," '어떻하죠',\n"," '에서',\n"," '여행',\n"," '으로',\n"," '이상해요',\n"," '있어요',\n"," '하고']"]},"metadata":{"tags":[]},"execution_count":46}]},{"cell_type":"markdown","metadata":{"id":"i_crBvw0dMO3","colab_type":"text"},"source":["말뭉치들이 잘 생성되었네요. 그러면 새로운 문장으로 다시 테스트 해봅시다."]},{"cell_type":"code","metadata":{"id":"U2TJFeAMdKkl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1598238811510,"user_tz":-540,"elapsed":957,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"d2a0ad90-abd2-4d51-c8ad-a40de1f70f0f"},"source":["new_post = ['근처 공원에 메리랑 놀러가고 싶네요.']\n","new_post_tokens = [okt.morphs(row) for row in new_post]\n","\n","new_post_for_vectorize = []\n","\n","for content in new_post_tokens: \n","  sentence = ''\n","  for word in content: \n","    sentence = sentence + ' ' + word \n","\n","  new_post_for_vectorize.append(sentence)\n","\n","new_post_for_vectorize"],"execution_count":47,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[' 근처 공원 에 메리 랑 놀러 가고 싶네요 .']"]},"metadata":{"tags":[]},"execution_count":47}]},{"cell_type":"markdown","metadata":{"id":"VF5L9PsfdP0u","colab_type":"text"},"source":["형태소 분석이 잘 되었구요, 이를 벡터화하여 새롭게 유사도를 측정해봅시다."]},{"cell_type":"code","metadata":{"id":"cTFCl5qldOFn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":160},"executionInfo":{"status":"ok","timestamp":1598238827029,"user_tz":-540,"elapsed":992,"user":{"displayName":"김보겸","photoUrl":"","userId":"10542318974879873360"}},"outputId":"d2980e06-b7c3-439a-e500-f992bf1d9a53"},"source":["best_doc = None \n","best_dist = 65535\n","best_i = None \n","\n","for i in range(0, num_samples): \n","  post_vec = X.getrow(i)\n","  d = dist_norm(post_vec, new_post_vec)\n","\n","  print(\"== post %i with dist=%.2f    : %s\" % (i,d,contents[i]))\n","\n","  if d < best_dist: \n","    best_dist = d\n","    best_i = i \n","\n","print(\"Best post is %i, dist = %.2f\" % (best_i, best_dist))\n","print('-->', new_post)\n","print('---->', contents[best_i])"],"execution_count":48,"outputs":[{"output_type":"stream","text":["== post 0 with dist=1.32    : 메리랑 놀러가고 싶지만 바쁜데 어떻하죠?\n","== post 1 with dist=0.43    : 메리는 공원에서 산책하고 노는 것을 싫어해요\n","== post 2 with dist=0.95    : 메리는 공원에서 노는 것도 싫어해요. 이상해요.\n","== post 3 with dist=1.33    : 먼 곳으로 여행을 떠나고 싶은데 너무 바빠서 그러질 못하고 있어요\n","Best post is 1, dist = 0.43\n","--> ['근처 공원에 메리랑 놀러가고 싶네요.']\n","----> 메리는 공원에서 산책하고 노는 것을 싫어해요\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-ZFg6LtYdskt","colab_type":"text"},"source":["이런 방식으로 벡터화를 해도 마찬가지로 '메리는 공원에서 산책하고 노는 것을 싫어해요'가 가장 높은 유사성을 보이네요^^\n","\n","휴... 머신러닝 맛보기 커리는 여기서 끝입니다. 이번 주차에는 공부할게 정말 많네요! 그래도 이게 다 피가되고 살이되는 그런겁니다~ ㅎㅎㅎ 지금은 이해못하더라도 아 이런 기법이 있구나 정도만 알아두시면 이번 교안은 잘 공부하신겁니다.\n","\n","다음 커리에서는 자연어처리를 실제로 어떻게 활용하는 법을 청와대 청원 크롤링 & 분석 프로젝트를 통해 익힐겁니다. 그럼 다음 커리에서 또 봐요~👨‍💻"]},{"cell_type":"code","metadata":{"id":"D6mKPAKldR34","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}